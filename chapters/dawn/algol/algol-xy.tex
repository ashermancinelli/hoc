
\subsection{ALGOL 68 (and X, Y, W, \dots)}

For years after the 1962 Rome meeting, there were discussions amongst the ALGOL
community about potential changes and improvements to the language.
The 1960 and 1962 meetings restricted themselves to clarifying ambiguities
and rectifying true errors in the prior reports, but not extensions or
significant changes.
In the March of 1964 as follow up to Rome meeting, they finally agreed to
start on ALGOL X and ALGOL Y, drafts of the language that would consider
significant changes and additions to the language.
ALGOL X would be intended to solve the issues of ALGOL 60 in the short-term,
compared to the "radically reconstructed future ALGOL Y"
\cite{cleaning_up_algol60_duncan_wijngaarden_1964}.

To summarize the following section: three draft reports were proposed,
Adriaan Van Wijngaarden was asked to revise his draft report until the other
two authors were satisfied,
the draft report that all three were satisfied with became canonized as ALGOL 68,
many people withdrew from the language community (formally or informally)
in reaction to the new language,
and the language was never widely adopted.

\input{chapters/dawn/algol-68-timeline.tex}

In 1965, the first three drafts for ALGOL X were proposed by
Niklaus Wirth (who benefitted from numerous comments from Tony Hoare),
Gerhard Seegmüller, and Adriaan van Wijngaarden.
Seegmüller's proposal was not too different from Wirth and Hoare's, which
was called ALGOL W, but
Wijngaarden's proposal was dramatically different.
Wijngaarden described his ALGOL X language in an entirely new
formal grammar which came to be known as a \textit{W-Grammar} (after his own namesake).

The impact of Wijngaarden's proposal on the development of ALGOL cannot be overstated.
In the spring of 1968, Adriaan van Wijngaarden released a draft report for ALGOL X
(which was, mind you, supposed to be the \textit{incremental} improvement to ALGOL 60)
based on Wirth and Hoare's ALGOL W but using his own W-Grammar.
% The discussions and meetings over ALGOL X overran such that the subsequent
% meeting on ALGOL Y was overtaken by discussion of ALGOL X.
In this time period, Peter Naur and Brian Randall of IBM even suggested that the incremental
ALGOL X be dropped entirely in favor of the more ambitious ALGOL Y.
At nearly every step, the committee ran significantly past their schedules:
"Throughout the whole project, the WG in general, and Van Wijngaarden in particular, consistently
underestimated the time it would take by substantial factors. Recall that ALGOL 60 was put together
in six days"\cite{a_history_of_algol_68_1993}.

Wijngaarden's ALGOL W proposal was distinct for at least three reasons:

\begin{enumerate}
	\item A two-level \textit{W Grammar}.
	\item "The combination of a minimal number of language concepts in an orthogonal way"
	      \cite{a_history_of_algol_68_1993}.
	\item Expression orientation; everything is an expression and has a value.
\end{enumerate}

% The first programming language designed by international committee receive
% significant interest and is still used in academia today, however it never
% gained significant traction.
% Outside of small snippets in academic papers, it was only ever in use by
% the Burroughs Corporation\cite{burroughs1963bac220},
% and their implementation required significant library
% development to provide their programers with an environment capable of doing
% much of anything useful.
The computer and aerospace historian Paul Ceruzzi describes the result of
the ALGOL 68 report as follows:

\begin{quotation}
	Whereas ALGOL-60 was based on a formal structure
	and was very lean, ALGOL-68 was burdened by an attempt to do too
	much, with the effects that some features interfered with the clean
	implementation of others. It was hard to understand. In an attempt to
	satisfy a broad range of users worldwide, the committee produced
	something that satisfied few.
\end{quotation}

Charles Lindsey, British computer scientist and editor of
\citep{revised_report_on_the_algorithmic_language_algol_68_1976}
(and numerous other texts on ALGOL 68) describes popular sentiment about the
report\cite{a_history_of_algol_68_1993}:
\begin{quotation}
	The world seems to have a rather negative perception of ALGOL 68. The language has been said to
	be "too big," to be defined by an "unreadable Report" produced by a committee which "broke up in
	disarray," to have no implementations, and to have no users.
\end{quotation}

This was not his opinion, however\cite{a_history_of_algol_68_1993}:

\begin{quotation}
	I should point out that my own involvement with the project came after the basic design of the
	language, and of its original Report, were complete\dots
	It is only now, in the course of studying the minutes and other
	documents from that time, that I have come to see what the real fuss was about, and I hope that all
	this has enabled me to take a dispassionate view of the events. The reader of this paper will certainly
	see discord, but I believe he will see also how good design can win through in the end.
\end{quotation}

Lindsey was appointed Lecturer in Computer Science at Manchester University
in 1967. Aside from his standardization efforts, he wrote a research implementations of
ALGOL 68 for the MU5, one of the Manchester computers, and he maintained an
implementation of a subset of ALGOL 68, \textit{ALGOL 68S}.
It is difficult to take Lindsey's opinions about ALGOL 68 entirely at face
value because so much of his career was dedicated to the language.
If we look at those involved with the design of ALGOL 68 who
had programming language design and compiler experience elsewhere,
we find his depiction above to be more accurate than not.

Another meeting in May 1967 in Zandvoort, Netherlands was intended to develop a direction for ALGOL Y,
however nearly all the discussion was about ALGOL X.
From the outset, the only language aspect the designers knew they wanted from ALGOL Y
was the ability for an ALGOL Y program to modify itself.
Lindsey remarks:

\begin{quotation}
	They even spent an afternoon on ALGOL Y, from which it emerged that no one had
	very concrete ideas of what it was about, and that the only role model was
	LISP, on account of the fact that that language could construct its own
	programs and then \textit{eval} them.
\end{quotation}

The largest single outpouring of criticism of ALGOL 68 came from
\citep{mr93_draft_report_on_algol_68_1968}, also known as [MR93].
Several members of the committee (including Peter Naur) resigned
after this report's circulation.
It was first circulated to the \textit{ALGOL Bulletin} in February 1968,
and "was the cause of much shock, horror, and dissent, even
(perhaps especially) among the membership of WG 2.1"\cite{a_history_of_algol_68_1993}.
Numerous papers were written in response to MR93, including Peter Naur's \textit{scathing}
critique \citetitle{successes_and_failures_of_the_algol_effort_naur_1968}.
His report was especially critical of the International Federation for Information Processing
(IFIP), which had formed a working-group (WG 2.1) responsible for specifying the language.

Also in response to MR93, Lindsey joined the language effort and
distributed his \citep{algol68_with_fewer_tears_1968}
in which he attempted to synthesize the nicer language hidden within the earlier reports
\footnote{For those unaware, this title is an homage to the English textbook \textit{French without Tears}.}.
He clarified a number of terms which appear to be specific to ALGOL, and
have well-understood meanings under different names in other languages.
For example, what ALGOL calls a \textit{name} is more commonly known as a reference or pointer;
numerous differences in nomenclature contributed to the difficulty of reading
the original reports.

Van Wijngaarden had circulated another
report\cite{penultimate_draft_report_on_algol_68_1968} in October of 1968 as he
had earlier promised the committee; at the same time, other members who
disagreed with the direction but had not resigned were also developing several
minority reports, include Dijkstra, Hoare, and Randell.
Sparing the reader the full details and political history of the ensuing committee
meetings, the final report \citetitle{report_on_the_algorithmic_language_algol_68_mailloux_1969}
was published in \textit{Numerische Mathematik} and \textit{Kybernetika}
in 1969, thus specifying what we know today to be ALGOL 68.

\subsection{The W-Grammar}

Before analyzing the technical details of ALGOL 68, we must first understand
what made it so offensive and uninterpretable to so many people: its grammar.

The primary reason for this grammar's complexity is that it encompasses
far more than compiler engineers typically associate with a grammar
in order to be \textit{formally context-sensitive}.
It is not merely a specification of the syntax of the language;
it also specifies a great deal of the \textit{semantics} of the language,
because that is required for the language to be context-sensitive.
When the grammar is described as \textit{two-level}, it communicates that the
grammar consists of two levels: the meta-grammar and the concrete grammar, and the
meta-grammar produces the concrete grammar.
Readers of [MR93] would need to keep track of both levels in order to understand
the document; meta-rules would need to be kept conceptually distinct in the reader's mind.
The \textit{format} of the grammar was also problematic and difficult to read,
but that may not have been so problematic had they not fit so many semantic concepts into the grammar.

When Wijngaarden first proposed his grammar, nobody had seen anything like it.
The authors attempted to formalize object lifetimes, variable scoping rules,
and relatively complicated type systems (even by today's standards), all without
the benefit of decades of research into type theory and formal semantics which
we have today.
Let the reader give the authors the benefit of the doubt; keep in mind they
attempted to formalize concepts for the first time, and subsequent research benefitted
greatly from their ideas (and mistakes).
The language specification was, effectively, a compiler front-end specification.

Lindsey argues that the grammar is relatively close to Prolog, where
goals and sub-goals are specified and solved for by unification
\footnote{The term \textit{unification} may be loaded; Milner did not publish
	his work on SML and type inference until later, though his work was inspired by
	ALGOL 68 to some degree.}.

Lindsey uses the following Prolog example to introduce a rule in ALGOL 68's W-grammar,
which asks whether the input program contains an assignation, and to determine this,
we must test if we have a destination, followed by some language construct that
becomes a symbol, followed by a source.

\begin{minted}{prolog}
assignation(ref(MODE)) :-
      destination(ref(MODE)), becomes_symbol, source(MODE).
\end{minted}

The corresponding rule in the [MR93] draft report is as follows
\cite{draft_report_algol_1968}:
\begin{minted}{ebnf}
MODE assignation :
    reference to MODE destination, becomes symbol, MODE source.
\end{minted}

Substituting \textbfit{int} for our \textbfit{MODE}, we have:
\begin{minted}{ebnf}
int assignation :
    reference to int destination, becomes symbol, int source.
\end{minted}

If you squint your eyes, maybe you can see how \textit{i := 5} fits the mold for this
grammar, where the \textbfit{MODE} is \textbfit{int}, the \textbfit{destination} is
the location of \textbfit{i} of mode \textbfit{ref int}, and the source is
the integer literal \textbfit{5} of \textbfit{MODE int}.
This may feel familiar, like a looser version of the Backus-Naur
syntax used by compiler-compilers.
The problem is, nearly anything else is also expressible in this grammar,
making it nearly impossible to write a parser based on an unrestricted W-grammar.

A more nebulous component of the original grammar from [MR93] can be found in
\textit{Section 4.4 Context Conditions},
which specified conditions for a program to be \textit{semantically valid}
based on the surrounding context.
Modern readers may find this strange; we are discussing the language \textit{syntax},
why is the report discussing the semantic validity of, for example,
the use of a particular identifier and its relationship to its declaration?
As we have already established, this is an example of language \textit{semantics}
being specified in the grammar.

Most modern compilers are broken into three parts: the front-end, middle-end
\footnote{Only compiler engineers could produce a term as idiosyncratic as \textit{"middle" "end"}.},
and back-end.
The front-end typically consumes the input program,
produces data structures representing the program,
and performs \textit{semantic} analysis on those data structures to ensure the program is valid.
The consumption of the input program is usually determined by the grammar specified by the language,
and semantic validity is determined by the language's type system and other rules,
but not typically by the grammar.
Because Wijngaarden attempted to specify all of this in the grammar itself,
the grammar needed to specify these semantic conditions as well.

See this excerpt on \textbfit{NEST}s from
\cite[Section 3.0.2, Semantics]{revised_report_on_the_algorithmic_language_algol_68_1976}:
\begin{quotation}
	A "nest" is a 'NEST'. The nest "of" a construct is the "NEST" enveloped
	by the original of that construct, but not by any 'defining LAYER'
	contained in that original.

		{The nest of a construct carries a record of all the declarations forming
			the environment in which that construct is to be interpreted.

			Those constructs which are contained in a range R, but not in any
			smaller range contained within R, may be said to comprise a "reach". All
			constructs in a given reach have the same nest, which is that of the
			immediately surrounding reach with the addition of one extra "LAYER".
			The syntax ensures (3.2.1.b, 3.4.1.i,j,k, 3.5.1.e, 5.4.1.1.b) that each 'PROP'
			(4.8.1.E) or "property" in the extra 'LAYER' is matched by a defining.
			indicator (4.8.1.a) contained in a definition in that reach.}
\end{quotation}

Today, \textbfit{NEST}s might exist concretely as data structures inside the semantic analysis
phase of a compiler, but in ALGOL 68, they were specified as part of the grammar itself.

ALGOL 68's type system was also remarkably complex and, again, fully embedded in the grammar.
Union modes are full commutative and accumalative types, meaning that
the following types are equivalent:
\textbfit{union(int, real, bool)},
\textbfit{union(real, int, bool)}, and
\textbfit{union(bool, union(real, int))}.

Lindsey pointed out a particularly tricky aspect of the type system in structural equivalence.
Structure types are equivalent if their members are equivalent, as opposed to name equivalence,
which would have implied two structures with the same members but different names
are not equivalent.
The following two types are equivalent by structural comparison:
\begin{minted}{pascal}
mode a = struct (int val,
                 ref a next);
mode b = struct (int val,
                 ref struct (int val, ref b next) next);
\end{minted}


\subsection{Concepts of ALGOL 68}

Having covered the political machinery that resulted in the final report and
the grammar that caused the community so much grief,
we will now look to more technical details of the language.

Firstly, ALGOL 68 is an expression-oriented language;
there is fundamentally no distinction between statements and expressions,
allowing for constructs like the following:

\begin{minted}{pascal}
x := (real a = p*q;
      real b = p/q;
      if a>b then a else b fi)
      + (y := 2*z);
\end{minted}

One of the key goals of the committee was to design language features that
would be \textit{orthogonal}--\citeauthor{programming_language_pragmatics_2009}
put it well in \cite{programming_language_pragmatics_2009}:

\begin{quotation}
	One of the principal design goals of Algol 68 was to make the various features
	of the language as orthogonal as possible. Orthogonality means that features can
	be used in any combination, the combinations all make sense, and the meaning
	of a given feature is consistent, regardless of the other features with which it is
	combined. The name is meant to draw an explicit analogy to orthogonal vectors
	in linear algebra: none of the vectors in an orthogonal set depends on (or can
	be expressed in terms of) the others, and all are needed in order to describe the
	vector space as a whole.
\end{quotation}

There were numerous extensions to arrays, including higher-dimensional arrays,
complicated slicing mechanisms, and flexible arrays, such as the following:
\begin{minted}{pascal}
loc[1:4, 1:5] int a45;
a45[2  ,    ] # row 2 #
a45[   , 3  ] # column 3 #
a45[2:3, 3  ] # part of column 3 #
a45[2:3, 2:4] # a little square in the middle.  #

loc flex [1:0] int array; # initially empty #
array := (1, 2, 3);       # now it has bounds [1:3] #
array := (4, 5, 6, 7, 8); # now it has bounds [1:5] #
\end{minted}

\Gls{call-by-name} as it was known in ALGOL 60 was removed in favor of
\gls{call-by-value} and \gls{call-by-reference}; some of the other proposals
(such as Seegm{\"u}ller's) preserved the two cases of call-by-name
under different terms, but this was not adopted.
One may argue that \textit{proceduring} is a form of call-by-name,
but this feature was removed in the revised report of 1973.

Call-by-name is really two different concepts:
call-by-reference (where the actual parameter is a named variable to
be assigned to) \textit{or} call-by-full-name (where the actual parameter
is an expression to be placed in a thunk and re-evaluated each time
it is used in the body of the callee). This meant that Jensen's Device
and other tricks made possible by call-by-name were no longer possible
in ALGOL 68.
Wirth's proposal included call-by-name untouched from ALGOL 60 alongside
a \textit{new} parameter passing mechanism called \textit{parameterless \textbf{procedure}}
parameters, meaning the parameters were thunks to be evaluated each time they
were used in the body of the callee\cite{a_history_of_algol_68_1993}.
Lindsey uses an inner-product algorithm to illustrate this:

\lstinputlisting[language=algol,frame=single]{chapters/dawn/inner-product.a68}

He notes that the first and second parameters are effectively both called by-name.
As far as I can tell, the only difference is that call-by-name parameters can
be \gls{l-value}s or \gls{r-value}s while parameterless procedures are always r-values.

There were at least eight changes to the automatic type conversion rules
between ALGOL 60 and ALGOL 68;
Lindsey had this remark about the automatic type conversion features:
\begin{quotation}
	Although coercions had existed in previous programming languages, it was ALGOL
	68 that introduced the term and endeavoured to make them a systematic feature
	(although it is often accused of a huge overkill in this regard).
\end{quotation}

Many of these coercion rules were uncontroversial; for example, a \textbfit{real}
may be assigned to a \textbfit{union(real, int)}.
\todo{Discuss \textit{rowing}? relates to rank polymorphism a bit...}
One particularly problematic coercion rule was \textit{proceduring}.
This allowed users to force call-by-name semantics by coercing an expression
into a parameterless procedure, like so:

\begin{minted}{pascal}
      PROC x plus 1 = INT : x + 1;
\end{minted}

The right hand side of this expression is a \textit{cast}
(a term originally coined for the specification of ALGOL)
of an integer expression into a procedure taking no arguments.
In \citetitle{algol68_with_fewer_tears_1968}
\footnote{This paper was, in fact, a valid ALGOL 68 program in and of itself},
Lindsey argues that references
obviate the need for call-by-name semantics, but that call-by-substitution is what
ALGOL 60's call-by-name effectively was, and this was still possible with ALGOL 68
via this \textit{proceduring} coercion:

\begin{minted}{pascal}
proc series = (int k, ref int i, proc real term) real expr
    begin
    real sum(0);
    for j to k do
        begin i := j;
              sum plus term
        end;
    sum
    end

x := series (100, i, real expr(1/i));

# Or, via proceduring: #
x := series (100, i, 1/i);
\end{minted}

This facility was abandoned in the ALGOL 68-R implementation which
led to its removal in the revised report of 1973,
as we will see in the next section.
There were still other mechanisms to achieve similar results,
as tricks like Jensen's Device had become important to the community.
One such example is the extensions to procedures.

Naur and Wirth both proposed block-expressions, meaning the final value in a block
is the value of the entire block in the context of an expression, and Naur's
1966 proposal (which was accepted) merged the formal parameters into the same line as
the parameters themselves, meaning one need not restate the types of parameters
at the beginning of the procedure body.
These two features allowed for convenient use of anonymous procedures capturing
parts of their surrounding context and procedures taking other procedures,
relatively advanced features even for today.
The revised report contains this example
\cite[Section 11.2, Innerproduct 1]{revised_report_on_the_algorithmic_language_algol_68_1976}:

\inputminted{modula2}{chapters/dawn/inner-product2.a68}

ALGOL 60 was the first programming language to permit
nested functions, a feature ALGOL 68 retained.
This meant that nested procedures had to be capable of capturing
their environments, dramatically complicating the work of the compiler
engineer (as did many of the language's features).
The compiler had to somehow pass the captured environment along with the
procedure so it had access to the state of the outer scope.
In C++ for example, lambda functions are really classes
which capture the enclosing scope as a member variable - no such facility
was specified in the language standard, so compiler authors were left to
sort it out themselves.

\subsection{ALGOL 68-R and the Revised Report}

In 1973, the \citetitle{revised_report_on_the_algorithmic_language_algol_68_1976} was published,
codifying some of the changes and rejected features from the ALGOL 68-R team.

\todo{look at peck's \citep{the_algol_68_story_peck_1978}}

His work on ALGOL 68S was not an outlier amongst would-be implementers of the
language; because the report was so large and complex, most
implementers ended up restricting themselves to a subset of the language.
