\section{Early Type Theory}
\label{sec:early-type-theory}

A surprising number of the foundations for type theory were laid before
many familiar programming concepts were developed.
Namely, Alonzo Church's \lambdacalc{} and Haskell Curry's combinatory logic
would set the foundation for type theory long before they would be implemented in
a proper compiler.

Let me digress for a moment before we begin.
We will also discuss the topics that I hold responsible for the general
bewilderment that most computer science students feel when they are first
introduced to programming concepts: the degree to which programming concepts
are arbitrary.
Computer science and software engineering are often taught like materials science,
where we have concrete methods for discovering and constructing new materials,
when in reality, programming is fundamentally built on \textit{information science},
not engineering.

When we superimpose meaning on the state of computers and the blueprints
we provide the computer in the form of code, we are not discovering new materials
but (often rather arbitrarily) assigning meaning based on analogies to the physical
world which may or may not be reflected in the machines themselves.
This is most obviously seen in object-oriented programming, where the state of
the machine is represented by objects and their platonic ideals so the programmer
can develop a more natural mental model of the machine.
The process of discovering which analogies work well for human comprehension
(and therefore which ones work well in compilers and programming language design)
is rather unscientific, and is often produced by programmers coming up with
ideas based on what works well in the field.

Type theory, category theory, information theory and the like all underpin
these decisions because they are also built entirely on top of information.
This is the reason information theoriests and category theorists are so
influential in the history of programming language design, and why their
work is often bewildering to programmers without a formal background
in these fields--even very experienced ones.

The full history of
% This section may therefore feel foreign--it still feels that way to me--
% so I encourage you to glean what you can from it, and to not be too
% troubled by what you cannot.

\subsection{Alonzo Church's \Lambdacalc{}}

We will not given an exhaustive look at Church's life and work outside of the
\lambdacalc{}--I encourage readers to consult \citetitlecite{stanford_encyclopedia_church_2025}
for this.
He is renowned for more than just the \lambdacalc{} though we will not cover much more
than that here.

Recall that the foundation of software is in information theory and
mathematics.
Alonzo Church was a mathematician who researched the foundations of mathematics
in the 1930s and 1940s,
\todo{history of lambda calc:
	\citetitle{cardone_hindley_history_of_lambda_calcl_2006},
	\citetitle{hindley_lambda_calc_intro_2008}

	history of lambda calc:
	Both lambdacalc and combinatory logic were invented in the 1920s.
	Describe most basic properties of functions. logical foundation of math was
	real fluid in early 19thc. Russell's paradox was recent G{\"o}del's theorems
	not known yet, still developing the foundations of math.
	Some were based on sets, some based on functions, all up in the air.
	lambda and CL were developed here, build higher concepts of functions
	based only on these two foundations.
	\citeauthor{cardone_hindley_history_of_lambda_calcl_2006} describe as chassis of bus in prog langs.
	lambda/cl gain purpose in these systems, like chassis; underpins things
	and isnt seen, doesn't have much value on its own.
	function-based higher-order logic is the real context, but we're already so far off
	topic and I'd like to get back to compilers soon as I can.
	Lots was developed in the 20s and 30s, then not much till the 60s
	largely cuz of connections with prog langs.

	notations for higher-order thinking about functions dates earlier,
	at least 1889 Giuseppe Peano on axioms for arithmetic.
	was not until Moses Sch{\"o}nfinkel developed basic combinators
	for functions (1924 sec 1) that we start to get combinatory logic.
	at gottingen germany, prob top math research group of the period.
	Pointed out f(x,y) could be (f(x))(y) where f returns func,
	now known as "currying." curry attributed to Scho.. many times but the name
	stuck.
	that was the last thing scho published on combinators, and by 1927 he was said
	to be mentally ill and institutionalized.
	his ideas cropped up again in jv neumann doctoral thesis
	on foundations of set theory (neumann 1025) but it was really function-based
	not set-based, and his axioms contained combinator-like operators (p225).
	not sure if JVN got this from scho or not, he didn't mention him
	and his ideas looked really different.

	next step in CL: haskell curry re-invented combinators.

	6.1 lisp

	1956-60 mccarthy lisp w function-abstraction.
	didn't have numbers, but just like lambda calc.
	substitution was not like lambdacalc bc dynamic binding, which helped
	interpreters but made programming really complicated.
	mccarthy contributed some back, including cond-exprs in functional formalism.

	6.2 peter landin

	early 60s PL proposed lambda terms to make constructs of a programming language
	algol 60 (landin 1965).
	algol block structure/identifier semantics matched lambdacalc, allowed
	ppl to look at lambda as a programming langauge.
	in parallel with this algol stuff, landin 1963 abstract machine
	for reducing lambda terms SECD-machine (1964, 1966a) of 4 components:
	stack for intermediate results, environment, control (code) driving the process
	and dump for showing the state of the program.
	the rules of his machine used call-by-value.
	would be followed up by further considerations of lambdacalc as a prog lang
	(Plotkin 1975).
	For the most part, other than McCarthy's papers,
	CL/lambda contributed to proglangs but not the other way around,
	until Corrado Bohm from 1960s on.
	bohm phd thesis w first description of complete compiler written in its own language
		[bohm 1954].


}

Throughout the 1930s, Church developed the \textit{\lambdacalc{}},
a formal definition of a \textit{higher-order, functional} programming language
built on only three concepts: functions, variables, and applications.
The language was \textit{higher-order} in that functions could be passed
as arguments to other functions, and functions could return other functions as results.
It was \textit{functional} in that function definition and application was the
primary abstraction in the language.

In the \lambdacalc{}, functions are given by $\lambda x. E$ where $x$ is the function's argument
and $E$ is the resulting expression. The result of the function is given by substituting the
argument for all occurances of $x$ in $E$. Function application is given by juxtaposition,
so $F x$ applies the function $F$ to the argument $x$.

Function definitions and applications are all assumed to take exactly one argument,
though there are syntaxes given for more:

\begin{align}
	\lambda x . (\lambda y . (\lambda z . E)) & \equiv \lambda x y z . E
	\tag{function definition}
	\\
	M N P x                                   & \equiv M (N (P x))
	\tag{function application}
\end{align}

In 1940, he published \citetitle{church_simple_theory_of_types_1940}
which would become the foundation for type theory.

The \lambdacalc{}

\subsection{Haskell Curry}

\todo{not sure how much we want to cover here}...
\citetitle{curry_functionality_in_combinatory_logic_1934}.
