
\chapter{Software, 1960-1980ish}
\todo{shit got crazy; became important, needs more focus/attention.}
\section{The Software Crisis}
\begin{quotation}
    Despite great strides in software, programming always seemed to be in a stateof crisis and always seemed to play catch-up to the advances in hardware. Thiscrisis came to a head in 1968, just as the integrated circuit and disk storagewere making their impact on hardware systems. That year, the crisis wasexplicitly acknowledged in the academic and trade literature and was thesubject of a NATO-sponsored conference that called further attention to it.Some of the solutions proposed were a new discipline of software engineering,more formal techniques of structured programming, and new programming languagesthat would replace the venerable but obsolete COBOL and FORTRAN. Although notmade in response to this crisis, the decision by IBM to sell its software andservices separately from its hardware probably did even more to address theproblem. It led to a commercial software industry that needed to producereliable software in order to survive. The crisis remained, however, and becamea permanent aspect of computing. Software came of age in 1968; the followingdecades would see further changes and further adaptations to hardware advances.
\cite{history_of_modern_computing_2003_ceruzzi}
\end{quotation}
\todo{DEC PDP-8 and PDP-11; IBM System/360 and OS/360; Multics; Unix; C}As the 1960s progressed, the notion of 
\textit{software} became more established,and the programs being written served the authors to a much greater extent.Prior to the 1960s, programs were often tailor-made for a specific machine.There was no hope of re-using the program on another machine.For most of the users, their organization had spent a considerable portionof their budget on their system, and they were expected to use it for a long time.Retargetable compilers did not exist.Michael Mahoney made a strong statement to this end rather early on 
\cite[The Structures of Computation]{the-first-computers-2002}:
\begin{quotation}
    The kinds of computers we have designed since 1945 and the kinds of programs wehave written for them reflect not the nature of the computer but the purposesand aspirations of the groups of people who made those designs and wrote thoseprograms, and the product of their work reflects not the history of thecomputer but the histories of those groups, even as the computer in many casesfundamentally redirected the course of those histories.
\end{quotation}
\begin{quotation}
    Despite great strides in software, programming always seemed to be in a stateof crisis and always seemed to play catch-up to the advances in hardware. Thiscrisis came to a head in 1968, just as the integrated circuit and disk storagewere making their impact on hardware systems. That year, the crisis wasexplicitly acknowledged in the academic and trade literature and was thesubject of a NATO-sponsored conference that called further attention to it.Some of the solutions proposed were a new discipline of software engineering,more formal techniques of structured programming, and new programming languagesthat would replace the venerable but obsolete COBOL and FORTRAN. Although notmade in response to this crisis, the decision by IBM to sell its software andservices separately from its hardware probably did even more to address theproblem. It led to a commercial software industry that needed to producereliable software in order to survive. The crisis remained, however, and becamea permanent aspect of computing. Software came of age in 1968; the followingdecades would see further changes and further adaptations to hardware advances.
\end{quotation}
\todo{1945 was too early for this strong of a statement;how can one argue that software reflected the authors when it was so dependent on the hardware?}
\section{Seymore Cray}
\begin{quotation}
    The CDC 160 and the Origins of the MinicomputerThe Whirlwind (a computer prototype built at MIT) had a word length of only 16 bits, but the story ofcommercial minicomputers really begins with an inventor associated with very large computers: SeymourCray. While at UNIVAC Cray worked on the Navy Tactical Data System (NTDS), a computer designed fornavy ships and one of the first transistorized machines produced in quantity. Around 1960 Control Data, thecompany founded in 1957 that Cray joined, introduced its model 1604, a large computer intended forscientific customers. Shortly thereafter CDC introduced the 160, designed
\cite{nothing_new_since_von_neumann_2000}
\end{quotation}
\section{The DEC VAX and the IBM System/360}
\begin{quotation}
    Through the 1980s the dominant mainframe architecture continues to be adescendent of the IBM Sytem/360, while the dominant mini was the DEC VAX, whichevolved as a 32 bit extension of the 16-bit PDP-11.
\cite{nothing_new_since_von_neumann_2000}
\end{quotation}
\section{Aho Before Bell Labs}
\section{Aho, Ullman, and Bell Labs}
\todo{Software (and compilers!) starts to become a real discipline!Ullman was older and further along than Aho, and Hopcraft came to Princeton and became Aho's advisor.}
\begin{quotation}
    One of the first people that I met at Princeton was a Columbia graduate by thename of Jeffrey Ullman. He had just gotten his undergraduate degree fromColumbia University and also had come to study digital systems in the EEdepartment at Princeton. So, he and I became close friends. When we graduatedfrom Princeton, we both joined the newly formed Computing Sciences ResearchCenter at Bell Labs. There we developed a lifelong collaboration on subjectsranging from algorithms, programming languages, to the very foundations ofcomputer science. I was very fortunate to have met some of the greatest peoplein the field and to have gotten to know them and work with them. You learn somuch by working with the best people in the field. So, I felt very blessedbecause I had this kind of background
\dots
Hsu: Before we jump into Bell Labs more deeply, could you maybe explain-- talk about your PhD thesis,but try to explain it to somebody who, maybe like a museum goer who doesn't really know much aboutcomputer science and linguistics.

Aho: This is interesting. As I mentioned, Hopcroft told me, "Find your own research problem." He didteach a course in automata and language theory, so I got introduced to formal language theory andautomata theory, at least, as it was known at that time. I was interested in programming languages andcompilers. What I noticed was that a programming language has a syntax and a semantics. All languageshave a syntax and a semantics. If you want to write a translator for a programming language, or even anatural language, you have to understand the syntax and semantics of your source language and thetarget language
\dots
Hansen: 1967, and you followed Ullman there. He had already joined Bell Labs before.

Aho: A few months before me.

Hansen: A few months before. And what group was it that you joined?

Aho: I was interviewed by a department head by the name of Doug McIlroy. He was an appliedmathematician from MIT. He had been at Bell Labs for a few years before me. Amongst other things, hehad coinvented macros for programming languages and he's also in this class of one of the smartestpeople I've ever met.Jeff wanted to go to academia a little bit earlier than I did, like many yearsearlier. He stayed at Bell Labs for a few years and went to PrincetonUniversity where he joined the faculty of the electrical engineeringdepartment, but he would come and spend one day a week consulting at Bell Labs.His consulting stint was he would come Fridays and sit in my office all day.The conversations that we'd have would range over all sorts of topics, andsometimes he'd mentioned that he was working on a problem with a colleague atPrinceton, and after describing the problem, I might say, "You're kidding," andhe said, "Oh, you're right. The solution is obvious, isn't it?" I don't knowwhether I would say dynamic programming or whatever, but several papers cameout of this intense collaboration, and we got to the point where we couldcommunicate with just a few words. We had a very large, shared symbol table.
\cite{aho_oral_history_2022}
\end{quotation}
\begin{quotation}
    But as Unix was being developed, Ken Thompson created the first two versions ofUnix using assembly language. He had joined Bell Labs at roughly the same time I had. He was theremaybe six months or so ahead of us, and he had been assigned to work on the Multics project that BellLabs was part of with MIT and GE. When Bell Labs got tired of pouring money into Multics and not gettingthe operating system that it had wanted, it abandoned the project and left Ken Thompson to his owndevices. Ken thought there were some good ideas in Multics. Being the genius that he was, he said, I cando it much more simply and much more elegantly. So he created a rudimentary version of Unix and thenkept writing and polishing it. Dennis Ritchie came on the scene. Ken had also created a programminglanguage, B. The B was maybe the first letter of BCPL. Who knows? But when Dennis Ritchie looked atit, he said, what B needs is a decent type system. So he put a decent type system on B, and created theC programming language. Thompson and Ritchie wrote the third version of Unix using the newly createdC programming language. I became an early adopter of C, and I had C wired in my fingertips, so I couldwrite C programs quite readily, and of course, there were all these neat tools that accompanied theprogramming environment on Unix. There were the text editors. I don't know whether you've ever heard ofthe ED editor or the QED editor that was at MIT as part of Multics. QED had regular expressions in it. Thistriggered my interest in regular expressions. Ken Thompson had written a program called grep for doingpattern matching on text files, and it had a very limited form of regular expressions when I encountered it.
\cite{aho_oral_history_2022}
\end{quotation}
\begin{quotation}
\textbf{Collaboration with Ullman}

Aho is best known for the textbooks he wrote with Ullman, his co-awardee. 
Thetwo were full time colleagues for three years at Bell Labs, but after 
goingback to Princeton as a faculty member Ullman continued to work one day a 
weekfor Bell.They retained an interest in the intersection of automata theory 
with formallanguage. In an early paper, Aho and Ullman showed how it was 
possible to makeKnuth's LR(k) parsing algorithm work with simple grammars that 
technically didnot meet the requirements of an LR(k) grammar. This technique 
was vital to theUnix software tools developed by Aho and his colleagues at Bell 
Labs. That wasjust one of many contributions Aho and Ullman made to formal 
language theoryand to the invention of efficient algorithms for lexical 
analysis, syntax analysis, code generation, and code optimization. They 
developed efficient algorithms for data-flow analysis that exploited the 
structure of "gotoless" programs, which were at the time just becoming the norm.
\cite{aho_turing_award_2020}
\end{quotation}
\begin{quotation}
\textbf{The Early History of Software, 1952-1968 101}

In the early 1960s computer science struggled to define itself and its 
purpose,in relation not only to established disciplines of electrical 
engineering andapplied mathematics, but also in relation to—and as something 
distinct from—theuse of computers on campus to do accounting, record keeping, 
and administrativework.58 Among those responsible for the discipline that 
emerged, ProfessorGeorge Forsythe of Stanford's mathematics faculty was 
probably the mostinfluential. With his prodding, a Division of Computer Science 
opened in themathematics department in 1961; in 1965 Stanford established a 
sepa-ratedepartment, one of the first in the country and still one of the 
mostwell-regarded.59
\cite{history_of_modern_computing_2003_ceruzzi}
\end{quotation}
\todo{Dragon book; all the books Aho, Ullman and others worked on together.}
\section{Compiler-Compilers}
\todo{Yacc and Lex made with Aho's help. then everyone started making mini languages.AWK. "Kernighan and Cherry developed a little language for specifyingmathematics called EQN using these tools"}
\begin{quotation}
    People started using the Kernighan and Lorinda Cherry EQN tool to specifymathematics in their documents and in the research papers that they were writing. They would feed theEQN specification into the typesetting program roff
\dots
Knuth adopted the EQN language toinclude in the TeX typesetting system, and in LaTeX. It's basically Kernighan and Cherry's way ofspecifying mathematics. These software tools had a great deal of influence, and Kernighan and Cherryenjoyed the fruits of parsing theory and formal language theory in using the tools Lex and Yacc to createtheir EQN typesetting language. Knuth has this saying that the best theory is motivated by practice andthe best practice by theory. I internalized that with my early experience in the Computing SciencesResearch Center because I found that the theory that we were developing in computer science could beapplied to document preparation systems, programming languages, compilers, and so on. It was really avery productive environment. I taught courses on compiler design at local universities, and then when Iwent to Columbia, I would teach the course on programming languages and their translators
\dots
I might point out that the first Fortran compiler developed by IBM in the 1950s took 18 staff years tocreate. In my programming languages and compilers course, I organized the students into teams of fouror five. Each team had to create their own programming language, and then write a translator for it, and inall the time that I taught the course for almost 25 years at Columbia to thousands of students, never did ateam failed to deliver a working compiler in the 15-week course, and I attribute that to the abstractions
\cite{aho_oral_history_2022}
\end{quotation}
\begin{quotation}
    Aho: Okay. AWK is a programming language that was created by me, Brian 
Kernighan, and PeterWeinberger.

Hsu: And it's your three initials that are in.

Aho: Yes. I'm the A in AWK. Weinberger is the W in AWK and Kernighan is the 
K in AWK.We thoughtthat it was just a throwaway tool for us, nobody really 
would be interested in it. But it's amazing how muchroutine data processing 
there is in the world.The reason thelanguage got to be known as AWK was because 
when our colleagues would see the three of us in oneoffice or another, and when 
they'd walk past the open door, they'd say, AWK, AWK, AWK as they weregoing 
down the corridor. So we had no choice but to call it AWK because of the 
good-natured ribbing wegot from our colleagues, and because at some Unix 
conference, they passed out t-shirts that had AWK,and the error message saying 
"bailing out on or near line five" on them.
\end{quotation}
\todo{Ratfor, AMPL, other Kernighan languages.}
\todo{continue with typesetting...}
\section{The Dragon Book}
\begin{quotation}
    Jeff had bought into this idea that it's good for your career to write a 
book about what you're workingon. In the '70s, with all this work on Unix and 
C, there was a lot of interest in creating new programminglanguages and 
compilers. As with the algorithms book, what we did was we performed research 
onefficient algorithms for parsing and for some of the other phases of 
compilation, wrote papers on thoseand presented them at conferences. But we 
took the important ideas that we developed and thecommunity had developed over 
several decades and codified them into what are now called the dragonbooks. The 
first dragon book was published in 1977.We did have theorems and proofs in the 
book, and Jeff had this brilliant idea thatthe book should have a cover with a 
fierce dragon on it representing the complexity of compiler design,and then a 
knight in armor with a lance. The armor and the lance were emblazoned with 
techniques fromformal language theory and compiler theory to slay the 
complexity of compiler design
\dots
In the 1980s, more was knownabout how to construct efficient compilers. We 
invited Ravi Sethi as a third coauthor, he was at Bell Labsat the time, to join 
us in creating the second version of the dragon book. In the first version, the 
dragonwas in red. This second version, the dragon was-- sorry. In the first 
version it was in green. In the secondversion the dragon was in red. What was 
interesting about the red dragon book was there was a moviethat was created in 
1995 titled Hackers with a young Angelina Jolie in it, and in the movie, there 
is theuber hacker that's explaining to the new hackers what you have to read to 
become an uber hacker. Heshows them 10 papers and books that you must read, and 
one of them was the red dragon book. Whenmy two children saw this movie, and 
they had seen the red dragon book at home, this is the first time theythought 
their old man was really something because he had one of his books in a 
Hollywood movie. Itshows what you have to do to impress your kids these days. 
The red dragon book was 800 pages. In2007, we invited Monica Lam as a fourth 
coauthor to create a third version of the dragon book that had apurple dragon 
on the cover and it was close to a thousand pages. None of us had the heart to 
write afourth book at this point because it just shows how much new knowledge 
had been created in the area ofprogramming languages and compilers and their 
translators, and we continued to do research in this areato keep up with it.
\cite{aho_oral_history_2022}
\end{quotation}
\todo{Bjarne Stroustrup, C++ (1979); Dennis Ritchie, C (1972); Ken Thompson, B (1969); Brian Kernighan, AWK (1977), AMPL (1976), co-author of The C Programming Language (1978)}
\section{Commoditization}
\todo{Bill Gates and Paul Allen (Microsoft) | Microsoft BASIC (1975) | 
Developed the first critical piece of commercial software for personal 
computers,establishing the doctrine that software should be a purchased, 
proprietarycommodity. Sun microsystems, each part of the company needed to sell 
to all the others,reason why their compiler was paid; proprietary Unix;}
\pagebreak
\section{Timeline}
\input{chapters/software-timeline.tex}
