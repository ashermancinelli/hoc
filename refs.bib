
% Wikipedia has been a useful collection of primary and secondary sources
% https://en.wikipedia.org/wiki/History_of_compiler_construction#cite_ref-8
% https://en.wikipedia.org/wiki/History_of_programming_languages

@book{new_history_of_modern_computing,
        address = {Cambridge [Massachusetts]},
        series = {History of computing},
        title = {A new history of modern computing},
        isbn = {9780262542906},
        abstract = {"Bringing the history of modern computing fully up to date, from new applications to scientific computation to video games and the ubiquitous smartphone"},
        language = {eng},
        publisher = {The MIT Press},
        author = {Haigh, Thomas and Ceruzzi, Paul E.},
        year = {2021},
}

@misc{did_grace_hopper_create_the_first_compiler_2022,
	title = {Did {Grace} {Hopper} {Create} the {First} {Compiler}? {Communications} of the {ACM}},
	shorttitle = {Did {Grace} {Hopper} {Create} the {First} {Compiler}?},
	url = {https://cacm.acm.org/blogcacm/did-grace-hopper-create-the-first-compiler/},
	language = {en-US},
	urldate = {2025-10-04},
	month = dec,
	year = {2022},
    author = {Bruderer, Herbert}
}

@book{kernighan_unix:_2020,
	address = {s. l.},
	title = {{UNIX}: a history and a memoir},
	isbn = {9781695978553},
	shorttitle = {{UNIX}},
	language = {eng},
	publisher = {Kindle Direct Publishing},
	author = {Kernighan, Brian W.},
	year = {2020},
}

@inproceedings{bauer_software_1968,
	address = {Garmisch, Germany},
	title = {SOFTWARE ENGINEERING},
	booktitle = {SOFTWARE ENGINEERING},
	url = {https://www.scrummanager.com/files/nato1968e.pdf},
	publisher = {NATO SCIENCE COMMITTEE},
	author = {Bauer, Friedrick and Naur, Peter and Randell, Brian},
	month = oct,
	year = {1968},
}

@misc{numba_cuda,
    author = {{NVIDIA Corporation}},
    title = {Numba CUDA},
	shorttitle = {Numba CUDA},
    year = {2024},
    publisher = {GitHub},
    howpublished = {\url{https://github.com/NVIDIA/numba-cuda/}},
    urldate = {2025-10-04},
    note = {The CUDA target for Numba}
}

@misc{jax-compiler,
  author = {JAX Authors},
  howpublished = {\url{https://github.com/jax-ml/jax}},
  title = {JAX: High performance array computing},
  year = {2024}
}

@inproceedings{lam_numba,
	address = {Austin Texas},
	title = {Numba: a {LLVM}-based {Python} {JIT} compiler},
	isbn = {9781450340052},
	shorttitle = {Numba},
	url = {https://dl.acm.org/doi/10.1145/2833157.2833162},
	doi = {10.1145/2833157.2833162},
	language = {en},
	urldate = {2025-10-04},
	booktitle = {Proceedings of the {Second} {Workshop} on the {LLVM} {Compiler} {Infrastructure} in {HPC}},
	publisher = {ACM},
	author = {Lam, Siu Kwan and Pitrou, Antoine and Seibert, Stanley},
	month = nov,
	year = {2015},
	pages = {1--6},
}

@inproceedings{triton_tillet,
	address = {Phoenix AZ USA},
	title = {Triton: an intermediate language and compiler for tiled neural network computations},
	isbn = {9781450367196},
	shorttitle = {Triton},
	url = {https://dl.acm.org/doi/10.1145/3315508.3329973},
	doi = {10.1145/3315508.3329973},
	language = {en},
	urldate = {2025-10-04},
	booktitle = {Proceedings of the 3rd {ACM} {SIGPLAN} {International} {Workshop} on {Machine} {Learning} and {Programming} {Languages}},
	publisher = {ACM},
	author = {Tillet, Philippe and Kung, H. T. and Cox, David},
	month = jun,
	year = {2019},
	pages = {10--19},
}

@inproceedings{llvm,
author = {Lattner, Chris and Adve, Vikram},
title = {LLVM: A Compilation Framework for Lifelong Program Analysis \& Transformation},
year = {2004},
isbn = {0769521029},
publisher = {IEEE Computer Society},
address = {USA},
abstract = {This paper describes LLVM (Low Level Virtual Machine),a compiler framework designed to support transparent, lifelongprogram analysis and transformation for arbitrary programs,by providing high-level information to compilertransformations at compile-time, link-time, run-time, and inidle time between runs.LLVM defines a common, low-levelcode representation in Static Single Assignment (SSA) form,with several novel features: a simple, language-independenttype-system that exposes the primitives commonly used toimplement high-level language features; an instruction fortyped address arithmetic; and a simple mechanism that canbe used to implement the exception handling features ofhigh-level languages (and setjmp/longjmp in C) uniformlyand efficiently.The LLVM compiler framework and coderepresentation together provide a combination of key capabilitiesthat are important for practical, lifelong analysis andtransformation of programs.To our knowledge, no existingcompilation approach provides all these capabilities.We describethe design of the LLVM representation and compilerframework, and evaluate the design in three ways: (a) thesize and effectiveness of the representation, including thetype information it provides; (b) compiler performance forseveral interprocedural problems; and (c) illustrative examplesof the benefits LLVM provides for several challengingcompiler problems.},
booktitle = {Proceedings of the International Symposium on Code Generation and Optimization: Feedback-Directed and Runtime Optimization},
pages = {75},
location = {Palo Alto, California},
series = {CGO '04}
}

@inproceedings{mlir,
  author={Lattner, Chris and Amini, Mehdi and Bondhugula, Uday and Cohen, Albert and Davis, Andy and Pienaar, Jacques and Riddle, River and Shpeisman, Tatiana and Vasilache, Nicolas and Zinenko, Oleksandr},
  booktitle={2021 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)}, 
  title={MLIR: Scaling Compiler Infrastructure for Domain Specific Computation}, 
  year={2021},
  volume={},
  number={},
  pages={2-14},
  keywords={Program processors;Buildings;Semantics;Hardware;Software;Generators;Optimization},
  doi={10.1109/CGO51591.2021.9370308}}

@inbook{backus_history_of_fortran,
author = {Backus, John},
title = {The history of Fortran I, II, and III},
year = {1978},
isbn = {0127450408},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800025.1198345},
booktitle = {History of Programming Languages},
pages = {25–74},
numpages = {50}
}

@inproceedings{rosen_altac_fortran_1961,
author = {Rosen, Saul},
title = {ALTAC, FORTRAN, and compatibility},
year = {1961},
isbn = {9781450373883},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800029.808498},
doi = {10.1145/800029.808498},
abstract = {One of the major aims in the development of universal or common problem-oriented languages has been to permit a user to make the transition from one computer to another without the necessity of a complete reprogramming job.The ALTAC compiler, compatible with FORTRAN II, has been used to implement such a transition from the IBM 704 to the PHILCO 2000 at a number of installations. To the best of my knowledge this is the first time that a compiler has assumed the major burden of transition from a large scale computer of one manufacturer to an even larger scale computer of another manufacturer.},
booktitle = {Proceedings of the 1961 16th ACM National Meeting},
pages = {22.201–22.204},
series = {ACM '61}
}

@misc{noauthor_biography_nodate,
	title = {Biography of {Grace} {Murray} {Hopper} {\textbar} {Office} of the {President}},
	url = {https://president.yale.edu/biography-grace-murray-hopper},
	language = {en},
	urldate = {2025-10-04},
}

@article{bellia_hierarchical_1981,
	title = {Hierarchical development of programming languages},
	volume = {18},
	copyright = {http://www.springer.com/tdm},
	issn = {0008-0624, 1126-5434},
	url = {http://link.springer.com/10.1007/BF02576358},
	doi = {10.1007/BF02576358},
	language = {en},
	number = {3},
	urldate = {2025-10-04},
	journal = {Calcolo},
	author = {Bellia, M.},
	month = sep,
	year = {1981},
	pages = {219--254},
}

@book{bentley_digitized:_2012,
	address = {Oxford},
	title = {Digitized: the science of computers and how it shapes our world},
	isbn = {9780199693795},
	shorttitle = {Digitized},
	abstract = {In this book the author tells the story of computer science, explaining how and why computers were invented, how they work, looking at real-world examples of computers in use, and considering what will happen in the future. There's a hidden science that affects every part of your life. You are fluent in its terminology of email, WiFi, social networking, and encryption. You use its results when you make a telephone call, access the Internet, use any factory-produced product, or travel in any modern car. The discipline is so new that some prefer to call it a branch of engineering or mathematics. But it is so powerful and world-changing that you would be hard-pressed to find a single human being on the planet unaffected by its achievements. The science of computers enables the supply and creation of power, food, water, medicine, transport, money, communication, entertainment, and most goods in shops. It has transformed societies with the Internet, the digitization of information, mobile phone networks and GPS (Global Positioning System) technologies. Here, the author explores how this young discipline grew from its theoretical conception by pioneers such as Turing, through its growth spurts in the Internet, its difficult adolescent stage where the promises of Artificial Intelligence (AI) were never achieved and dot-com bubble burst, to its current stage as a (semi)mature field, now capable of remarkable achievements. Charting the successes and failures of computer science through the years, he discusses what innovations may change our world in the future},
	language = {eng},
	publisher = {Oxford university press},
	author = {Bentley, Peter J.},
	year = {2012},
}

@article{10.1145/99164.99179,
author = {Whitfield, D. and Soffa, M. L.},
title = {An approach to ordering optimizing transformations},
year = {1990},
issue_date = {Mar. 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {3},
issn = {0362-1340},
url = {https://doi.org/10.1145/99164.99179},
doi = {10.1145/99164.99179},
abstract = {As an approach to deriving an application order of optimizing transformations, a framework is developed for examining the interactions of the transformations. The framework is based on an axiomatic specification technique and includes both pre-conditions and post conditions that must exist before and after applying optimizations. For a selected set of optimizations, the framework is used to determine those interactions among the optimizations that can create conditions and those that can destroy conditions for applying other optimizations. From these interactions, an application order is derived to obtain the potential benefits of the optimizations that can be applied to a program. In some cases, the ordering of a pair of optimizations is unambiguous in that one optimization can either create or destroy the conditions for the other. In the few cases where there is a cyclic interaction, the ordering is resolved based on the perceived importance of the two optimizations.},
journal = {SIGPLAN Not.},
month = feb,
pages = {137–146},
numpages = {10}
}

@inproceedings{Whitfield1990,
author = {Whitfield, D. and Soffa, M. L.},
title = {An approach to ordering optimizing transformations},
year = {1990},
isbn = {0897913507},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/99163.99179},
doi = {10.1145/99163.99179},
abstract = {As an approach to deriving an application order of optimizing transformations, a framework is developed for examining the interactions of the transformations. The framework is based on an axiomatic specification technique and includes both pre-conditions and post conditions that must exist before and after applying optimizations. For a selected set of optimizations, the framework is used to determine those interactions among the optimizations that can create conditions and those that can destroy conditions for applying other optimizations. From these interactions, an application order is derived to obtain the potential benefits of the optimizations that can be applied to a program. In some cases, the ordering of a pair of optimizations is unambiguous in that one optimization can either create or destroy the conditions for the other. In the few cases where there is a cyclic interaction, the ordering is resolved based on the perceived importance of the two optimizations.},
booktitle = {Proceedings of the Second ACM SIGPLAN Symposium on Principles \&amp; Practice of Parallel Programming},
pages = {137–146},
numpages = {10},
location = {Seattle, Washington, USA},
series = {PPOPP '90}
}

@article{10.1145/99164.99179,
author = {Whitfield, D. and Soffa, M. L.},
title = {An approach to ordering optimizing transformations},
year = {1990},
issue_date = {Mar. 1990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {3},
issn = {0362-1340},
url = {https://doi.org/10.1145/99164.99179},
doi = {10.1145/99164.99179},
abstract = {As an approach to deriving an application order of optimizing transformations, a framework is developed for examining the interactions of the transformations. The framework is based on an axiomatic specification technique and includes both pre-conditions and post conditions that must exist before and after applying optimizations. For a selected set of optimizations, the framework is used to determine those interactions among the optimizations that can create conditions and those that can destroy conditions for applying other optimizations. From these interactions, an application order is derived to obtain the potential benefits of the optimizations that can be applied to a program. In some cases, the ordering of a pair of optimizations is unambiguous in that one optimization can either create or destroy the conditions for the other. In the few cases where there is a cyclic interaction, the ordering is resolved based on the perceived importance of the two optimizations.},
journal = {SIGPLAN Not.},
month = feb,
pages = {137–146},
numpages = {10}
}

@inproceedings{10.1145/99163.99179,
author = {Whitfield, D. and Soffa, M. L.},
title = {An approach to ordering optimizing transformations},
year = {1990},
isbn = {0897913507},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/99163.99179},
doi = {10.1145/99163.99179},
abstract = {As an approach to deriving an application order of optimizing transformations, a framework is developed for examining the interactions of the transformations. The framework is based on an axiomatic specification technique and includes both pre-conditions and post conditions that must exist before and after applying optimizations. For a selected set of optimizations, the framework is used to determine those interactions among the optimizations that can create conditions and those that can destroy conditions for applying other optimizations. From these interactions, an application order is derived to obtain the potential benefits of the optimizations that can be applied to a program. In some cases, the ordering of a pair of optimizations is unambiguous in that one optimization can either create or destroy the conditions for the other. In the few cases where there is a cyclic interaction, the ordering is resolved based on the perceived importance of the two optimizations.},
booktitle = {Proceedings of the Second ACM SIGPLAN Symposium on Principles \&amp; Practice of Parallel Programming},
pages = {137–146},
numpages = {10},
location = {Seattle, Washington, USA},
series = {PPOPP '90}
}

@article{bacon_compiler_1994,
author = {Bacon, David F. and Graham, Susan L. and Sharp, Oliver J.},
title = {Compiler transformations for high-performance computing},
year = {1994},
issue_date = {Dec. 1994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {26},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/197405.197406},
doi = {10.1145/197405.197406},
abstract = {In the last three decades a large number of compiler transformations for optimizing programs have been implemented. Most optimizations for uniprocessors reduce the number of instructions executed by the program using transformations based on the analysis of scalar quantities and data-flow techniques. In contrast, optimizations for high-performance superscalar, vector, and parallel processors maximize parallelism and memory locality with transformations that rely on tracking the properties of arrays using loop dependence analysis.This survey is a comprehensive overview of the important high-level program restructuring techniques for imperative languages, such as C and Fortran. Transformations for both sequential and various types of parallel architectures are covered in depth. We describe the purpose of each transformation, explain how to determine if it is legal, and give an example of its application.Programmers wishing to enhance the performance of their code can use this survey to improve their understanding of the optimizations that compilers can perform, or as a reference for techniques to be applied manually. Students can obtain an overview of optimizing compiler technology. Compiler writers can use this survey as a reference for most of the important optimizations developed to date, and as bibliographic reference for the details of each optimization. Readers are expected to be familiar with modern computer architecture and basic program compilation techniques.},
journal = {ACM Comput. Surv.},
month = dec,
pages = {345-420},
numpages = {76},
keywords = {vectorization, superscalar processors, parallelism, optimization, multiprocessors, locality, dependence analysis, compilation}
}

@misc{henry_comp.compilers:_nodate,
	title = {Comp.compilers: {Re}: {History} and evolution of compilers},
	url = {https://compilers.iecc.com/comparch/article/97-10-017},
	abstract = {From comp.compilers newsgroup: Re: History and evolution of compilers},
	urldate = {2025-10-04},
	author = {Henry, Spencer},
}

@misc{norman_grace_nodate,
	title = {Grace {Hopper} and {Colleagues} {Introduce} {COBOL}},
	url = {https://www.historyofinformation.com/detail.php?id=778},
	author = {Norman, Jeremy},
}

@book{laplante_encyclopedia_2017,
	address = {BOCA RATON},
	edition = {Second edition.},
	title = {Encyclopedia of computer science and technology. {Volume} {II}, {Fuzzy}-{XML}},
	isbn = {9781315115887},
	abstract = {This book covers all aspects of computer science, engineering, and technology. It includes computer scientists, computer engineers computing professionals, managers, software professionals, and other technology professionals.},
	language = {eng},
	publisher = {CRC Press},
	author = {Laplante, Phillip A.},
	year = {2017},
	note = {OCLC: 1032027866},
	keywords = {Information technology Encyclopedias, Computer science Encyclopedias},
}

@article{bergin_history_1996,
	title = {History of programming languages. 2 / ed. by {Thomas} {J}. {Bergin} and {Richard} {G}. {Gibson}},
	language = {eng},
	editor = {Bergin, Thomas J. and Gibson, Richard G.},
	year = {1996},
}

@article{landin_next_1966,
	title = {The next 700 programming languages},
	volume = {9},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/365230.365257},
	doi = {10.1145/365230.365257},
	abstract = {A family of unimplemented computing languages is described that is intended to span differences of application area by a unified framework. This framework dictates the rules about the uses of user-coined names, and the conventions about characterizing functional relationships. Within this framework the design of a specific language splits into two independent parts. One is the choice of written appearances of programs (or more generally, their physical representation). The other is the choice of the abstract entities (such as numbers, character-strings, list of them, functional relations among them) that can be referred to in the language.
            The system is biased towards “expressions” rather than “statements.” It includes a nonprocedural (purely functional) subsystem that aims to expand the class of users' needs that can be met by a single print-instruction, without sacrificing the important properties that make conventional right-hand-side expressions easy to construct and understand.},
	language = {en},
	number = {3},
	urldate = {2025-10-04},
	journal = {Communications of the ACM},
	author = {Landin, P. J.},
	month = mar,
	year = {1966},
	pages = {157--166},
}

@article{10.1145/321992.322001,
author = {Aho, A. V. and Johnson, S. C. and Ullman, J. D.},
title = {Code Generation for Expressions with Common Subexpressions},
year = {1977},
issue_date = {Jan. 1977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {1},
issn = {0004-5411},
url = {https://doi.org/10.1145/321992.322001},
doi = {10.1145/321992.322001},
abstract = {This paper shows the problem of generating optimal code for expressions containing common subexpressions is computationally difficult, even for simple expressions and simple machines. Some heuristics for code generation are given and their worst-case behavior is analyzed. For one register machines, an optimal code generation algorithm is given whose time complexity is linear in the size of an expression and exponential only in the amount of sharing.},
journal = {J. ACM},
month = jan,
pages = {146–160},
numpages = {15}
}

@book{10.5555/6448,
author = {Aho, Alfred V. and Sethi, Ravi and Ullman, Jeffrey D.},
title = {Compilers: principles, techniques, and tools},
year = {1986},
isbn = {0201100886},
publisher = {Addison-Wesley Longman Publishing Co., Inc.},
address = {USA}
}

@article{10.1145/29873.29875,
author = {Allen, Randy and Kennedy, Ken},
title = {Automatic translation of FORTRAN programs to vector form},
year = {1987},
issue_date = {Oct. 1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {4},
issn = {0164-0925},
url = {https://doi.org/10.1145/29873.29875},
doi = {10.1145/29873.29875},
abstract = {The recent success of vector computers such as the Cray-1 and array processors such as those manufactured by Floating Point Systems has increased interest in making vector operations available to the FORTRAN programmer. The FORTRAN standards committee is currently considering a successor to FORTRAN 77, usually called FORTRAN 8x, that will permit the programmer to explicitly specify vector and array operations.Although FORTRAN 8x will make it convenient to specify explicit vector operations in new programs, it does little for existing code. In order to benefit from the power of vector hardware, existing programs will need to be rewritten in some language (presumably FORTRAN 8x) that permits the explicit specification of vector operations. One way to avoid a massive manual recoding effort is to provide a translator that discovers the parallelism implicit in a FORTRAN program and automatically rewrites that program in FORTRAN 8x.Such a translation from FORTRAN to FORTRAN 8x is not straightforward because FORTRAN DO loops are not always semantically equivalent to the corresponding FORTRAN 8x parallel operation. The semantic difference between these two constructs is precisely captured by the concept of dependence. A translation from FORTRAN to FORTRAN 8x preserves the semantics of the original program if it preserves the dependences in that program.The theoretical background is developed here for employing data dependence to convert FORTRAN programs to parallel form. Dependence is defined and characterized in terms of the conditions that give rise to it; accurate tests to determine dependence are presented; and transformations that use dependence to uncover additional parallelism are discussed.},
journal = {ACM Trans. Program. Lang. Syst.},
month = oct,
pages = {491–542},
numpages = {52}
}

@book{10.5555/1097042,
author = {Cocke, John},
title = {Programming languages and their compilers: Preliminary notes},
year = {1969},
isbn = {B0007F4UOA},
publisher = {New York University},
address = {USA}
}

@techreport{allen_catalogue_1971,
	title = {A {Catalogue} of {Optimizing} {Transformations}},
	url = {https://www.clear.rice.edu/comp512/Lectures/Papers/1971-allen-catalog.pdf},
	institution = {IBM J Watson Research Center},
	author = {Allen, Francis and Cocke, John},
	year = {1971},
}

@inproceedings{backus_fortran_1957,
	address = {Los Angeles, California},
	title = {The {FORTRAN} automatic coding system},
	copyright = {https://www.acm.org/publications/policies/copyright\_policy\#Background},
	url = {http://portal.acm.org/citation.cfm?doid=1455567.1455599},
	doi = {10.1145/1455567.1455599},
	language = {en},
	urldate = {2025-10-04},
	booktitle = {Papers presented at the {February} 26-28, 1957, western joint computer conference: {Techniques} for reliability on - {IRE}-{AIEE}-{ACM} '57 ({Western})},
	publisher = {ACM Press},
	author = {Backus, J. W. and Stern, H. and Ziller, I. and Hughes, R. A. and Nutt, R. and Beeber, R. J. and Best, S. and Goldberg, R. and Haibt, L. M. and Herrick, H. L. and Nelson, R. A. and Sayre, D. and Sheridan, P. B.},
	year = {1957},
	pages = {188--198},
}
