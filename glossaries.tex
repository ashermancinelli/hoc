\makeglossaries

\newglossaryentry{bytecode}{
	name={bytecode},
	description={A compiler intermediate representation for the purpose of interpretation or execution instead of optimization}
}

\newglossaryentry{sift}{
	name={sift},
	description={The process of automatically translating code in one high-level language to another, preserving semantics and pointing out components of the source code that must be manually translated}
}

\newglossaryentry{bootstrap}{
	name={bootstrap},
	description={The process of writing a compiler in the language that it compiles, such that an older version of the compiler can be used to compile a newer version of itself}
}

\newglossaryentry{stride1}{
	name={stride 1},
	description={An array access pattern where the innermost loop iterates over the array elements in contiguous memory locations}
}

\newglossaryentry{ub}{
	name={undefined behavior},
	description={Source code constructs that are illegal as per the language's specification. Typically, undefined behavior assumed never to happen in a well-formed program, is used by optimizers when certain compiler flags are enabled (such as \texttt{-fstrict-aliasing})}
}

\newglossaryentry{F77}{
	name={Fortran 77},
	description={The 1977 version of the Fortran programming language's standard}
}

\newglossaryentry{F90}{
	name={Fortran 90},
	description={The 1990 version of the Fortran programming language's standard}
}

\newglossaryentry{foss}{
	name={FOSS},
	description={Free and open-source software. This software is typically distributed under a license that allows users to modify and redistribute it freely, though different licenses imply different permissions. The two primary categories of open-source licenses are \textit{permissive} and \textit{copyleft}}
}

\newglossaryentry{ftn}{
	name={Fortran},
	description={The Fortran programming language, standing for \textit{FORmula TRANslator}. Most renditions of the name of the programming language have only the first letter capitalized (\textit{Fortran}), however early versions were rendered as \textit{FORTRAN}. We attempt to use the proper name for each time period. \textit{Fortran} came to be used after the 1990 edition of the standard, while the 1977 standard and all prior versions were rendered as \textit{FORTRAN}}
}

\newglossaryentry{inducvar}{
	name={induction variable},
	description={A variable changes by some constant in each iteration of a loop. In \texttt{for (int i=0; i < n; i++)}, the variable \texttt{i} is an induction variable}
}

\newglossaryentry{constant-folding}{
	name={constant folding},
	description={Optimization that replaces an expression with a constant value if the expression's value can be determined at compile time. For example, the expression \texttt{2 + 3} can be replaced with \texttt{5} by the compiler so it need not be calculated by the final program}
}

\newglossaryentry{loop-versioning}{
	name={loop versioning},
	description={TODO}
}

\newglossaryentry{translation-unit}{
	name={translation unit},
	description={A component of a program being compiled such that the compiler has access to all the information contained in the component during compilation. For C, C++ and Fortran code, a translation unit typically corresponds to a single source file which is compiled to an object file before being linked into a program or library. Some compilers always treat the entire program as a single translation unit, like the original FORTRAN compiler or the Zig compiler}
}

\newglossaryentry{tripcount}{
	name={trip count},
	description={The number of times a loop will execute}
}

\newglossaryentry{inline-assembly}{
	name={inline assembly},
	description={A programming language feature that allows a programmer to write assembly code directly within another programming language, reading from and writing to variables in the host programming language}
}

\newglossaryentry{separable-compilation}{
	name={separable compilation},
	description={A programming paradigm where a program is divided into multiple modules that can be compiled independently. For example, C source files can be compiled independently, and then linked together to form an executable.}
}

\newglossaryentry{basicblock}{
	name={basic block},
	description={In compiler theory, a basic block is typically a sequence of instructions that are executed in order and containing a single entry point and exit point}
}

\newglossaryentry{backedge}{
	name={back-edge},
	description={A back-edge is an edge in the \acrshort{cfg} that returns execution from the end of a loop body back to the beginning of the loop, or the loop's \gls{header-cfg}}
}

\newglossaryentry{header-cfg}{
	name={header},
	description={A header is the first node in a control-flow graph of a loop. Loops begin execution at the entry node, then to the header node, then through the loop body node(s), and finally they either take the \gls{backedge} back to the start of the loop, or they exit the loop}
}

\newglossaryentry{r-value}{
	name={r-value},
	description={An value that can be stored to an address. Read as "a value that may occur on the right-hand side of an assignment." In most programming languages, l-values may act as r-values, but not all r-values may act as l-values. The variable \texttt{foo} may occur on either side of an assignment, but there is little sense in the number \texttt{5} being assigned a value}
}

\newglossaryentry{l-value}{
	name={l-value},
	description={An addressable value that another value can be stored to. Read as "a value that may occur on the left-hand side of an assignment"}
}

\newglossaryentry{dynamic-binding}{
	name={dynamic binding},
	description={Variable scoping semantics where the value of a variable is determined by the value the variable name corresponds to in the program's environment when the value is used.}
}

\newglossaryentry{call-by-name}{
	name={call-by-name},
	description={Function calling semantics where the argument's expression is evaluated \textit{each time it is used} in the body of the function. Contrast this with \gls{call-by-value} and \gls{dynamic-binding}}
}

\newglossaryentry{call-by-value}{
	name={call-by-value},
	description={Function calling semantics where the argument's expression is evaluated \textit{once, before it is passed} to the body of the function. Contrast this with \gls{call-by-name} and \gls{dynamic-binding}. This is how most programming languages work}
}

\newglossaryentry{call-by-reference}{
	name={call-by-reference},
	description={Function calling semantics where the argument's address is passed in place of its value such that expressions and statements where the parameter occurs as an \gls{l-value} result in assignements to the variable's storage in the caller's scope}
}

\newglossaryentry{offline-compilation}{
	name={offline compilation},
	description={todo}
}

\newglossaryentry{online-compilation}{
	name={online compilation},
	description={todo}
}

\newglossaryentry{forward}{
	name={forward},
	description={A compiler optimization where a load of a memory reference is replaced by the value last stored to it. Sometimes called forward substitution}
}

\newglossaryentry{strength-reduction}{
	name={strength reduction},
	description={A compiler optimization \todo{todo}}
}

\newglossaryentry{autovec}{
	name={automatic vectorization},
	description={A process for leveraging \acrshort{simd} instructions where the compiler \textit{infers} the opportunities to exploit parallelism in the user's program. The user does not \textit{necessarily} have to change their program, but they can often benefit from it or provide compiler flags or preprocessor directives to explicitly request it}
}

\newglossaryentry{lisp-machine}{
	name={Lisp machine},
	description={A type of computer designed to run Lisp as the primary programming language, usually with some level of hardware support}
}

\newglossaryentry{sexpr}{
	name={s-expression},
	description={A data structure used to represent arbitrary lists in Lisp, such as \textit{(a b c)}.
			Some tools and programming languages outside of Lisp use s-expressions to represent lists
			and list-like data structures}
}

\newglossaryentry{normal-form}{
	name={normal form},
	description={Many optimizations rely on the program being in the simplest possible form.
			Just as we expect fractions to be in their simplest form (it would be unusual to see
			$\frac{5}{10}$\textsuperscript{ths}), optimizations often expect or require their input
			programs to be as reduced as possible form to be maximally effective.
			% See \href{https://llvm.org/docs/LoopTerminology.html#loop-simplify-form}{LLVM's loop simplify form}
			for an example}
}

\newglossaryentry{canonical-form}{
	name={canonical form},
	description={See \gls{normal-form}}
}

\newglossaryentry{peephole}{
	name={peephole optimization},
	description={Sometimes called a \textit{peep}, this kind of transformation typically
			traverses the entire program searching for a small pattern that can be simplified or otherwise
			transformed in a beneficial way}
}

\newacronym[
	description={The internal format of a program as it exists inside the compiler}
]{ir}{IR}{intermediate representation}

\newacronym[description={}]{cl}{CL}{combinatory logic}

\newacronym[
	description={A tree representation of the program after being parsed}
]{ast}{AST}{abstract syntax tree}

\newacronym[
	description={A compilation methodology where the program is compiled as it is needed by the program instead of ahead of time. See also \gls{online-compilation}}
]{jit}{JIT}{just-in-time}

\newacronym[
	description={A methodology for performing the same operation on multiple pieces of data at the same time. With SIMD operations on a CPU data is usually stored in \textit{vectors} and entire vectors are processed at the same time via vector instructions. Often achieved with \gls{autovec} or explicit use of SIMD instructions with compiler intrinsics or inline assembly}
]{simd}{SIMD}{single instruction, multiple data}

\newacronym[
	description={A methodology for parallel computing where a set of identical instructions are dispatched to multiple threads to process the same data. This is how most GPUs are programmed at the lowest level (with CUDA for example). SIMT is akin to an advanced, predicated form of \acrshort{simd}}
]{simt}{SIMT}{single instruction, multiple thread}

\newacronym[
	description={todo}
]{spmd}{SPMD}{single program, multiple data}

\newacronym[
	description={A format for \acrshort{ir}s where there are infinite registers, and each can be assigned to only once}
]{ssa}{SSA}{static single assignment}

\newacronym[
	description={todo}
]{risc}{RISC}{reduced instruction set computer}

\newacronym[
	description={In compiler theory, the control-flow graph is a directed graph representing the possible paths of control flow through a program. Nodes of the graph are usually \gls{basicblock}s}
]{cfg}{CFG}{control-flow graph}

\newacronym[
	description={A compiler optimization that removes code that is never executed}
]{dce}{DCE}{dead code elimination}

\newacronym[
	description={A low-level \acrlong{ir} used to symbolically represent machine instructions in a target-independent format}
]{rtl}{RTL}{register transfer language}

\newacronym[
	description={A compiler analysis pass that determines how values change across iterations of a loop}
]{scev}{SCEV}{scalar evolution}

\newglossaryentry{pgo}{
	name={profile-guided optimization},
	description={Compiler optimizations that take advantage of statistics from the execution of a program to improve the compiler's heuristics. A user might compile and run a very program with special compiler flags such that loop hotness and \gls{tripcount}s are recorded, and then re-compile their program such that the compiler can use those statistics to drive its optimization decisions}
}

\newglossaryentry{licm}{
	name={loop-invariant code motion},
	description={Loop-invariant code motion is an optimization that moves code outside of a loop if it does not depend in any way on the loop's \gls{inducvar}s}
}
